{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "table2text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zb8QfOIVjUTGT-PQMzn7nbiDLqQHcEwI",
      "authorship_tag": "ABX9TyNZxhTLaixCdxClQddOpD8X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashantmishra311/Attentive-Seq2Seq-with-Copying-Mechanism-for-Table-to-text/blob/master/table2text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X97_Jm9CRAe"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-aPUH38EyI6"
      },
      "source": [
        "class Vocab(object):\n",
        "\n",
        "    def __init__(self, corpus, num_words=None, min_freq=None, unk_token='<unk>', pad_token='<pad>', sos_token=None, eos_token=None):\n",
        "\n",
        "        self.unk_token = unk_token\n",
        "        self.pad_token = pad_token\n",
        "        self.sos_token = sos_token\n",
        "        self.eos_token = eos_token\n",
        "        self.word_to_id = {}\n",
        "        self.id_to_word = {}\n",
        "\n",
        "        words = [unk_token, pad_token]\n",
        "        words = words.append(sos_token) if sos_token is not None else words\n",
        "        words = words.append(eos_token) if eos_token is not None else words\n",
        "        count = 0\n",
        "\n",
        "        for word in words:\n",
        "            self.word_to_id[word] = count\n",
        "            self.id_to_word[count] = word\n",
        "            count += 1\n",
        "        \n",
        "        size = num_words-len(words) if num_words is not None else num_words\n",
        "        self.word_freq = {word: freq for (word, freq) in self._construct_vocab(corpus, size, min_freq).items()}\n",
        "\n",
        "        for (word, freq) in self.word_freq.items():\n",
        "            self.word_to_id[word] = count\n",
        "            self.id_to_word[count] = word\n",
        "            count += 1\n",
        "        \n",
        "        self.vocab_size = count\n",
        "\n",
        "    def source_to_ids(self, text):\n",
        "\n",
        "        ids, oovs = [], []\n",
        "        for word in text:\n",
        "            try:\n",
        "                id = self.word_to_id[word]\n",
        "                ids.append(id)\n",
        "            except:\n",
        "                id = self.word_to_id[self.unk_token]\n",
        "                if word not in oovs:\n",
        "                    oovs.append(word)\n",
        "                ids.append(self.vocab_size + oovs.index(word))\n",
        "        \n",
        "        return ids, oovs\n",
        "\n",
        "    def caption_to_ids(self, text, source_oovs):\n",
        "\n",
        "        ids = []\n",
        "        for word in text:\n",
        "            try:\n",
        "                id = self.word_to_id[word]\n",
        "                ids.append(id)\n",
        "            except:\n",
        "                if word in source_oovs:\n",
        "                    ids.append(self.vocab_size + source_oovs.index(word))\n",
        "                else:\n",
        "                    ids.append(self.word_to_id[self.unk_token])\n",
        "        \n",
        "        return ids\n",
        "    \n",
        "    def ids_to_caption(self, ids, source_oovs):\n",
        "\n",
        "        words = []\n",
        "        for id in ids:\n",
        "            try:\n",
        "                word = self.id_to_word[id]\n",
        "                words.append(word)\n",
        "            except:\n",
        "                oov_id = id - self.vocab_size\n",
        "                try:\n",
        "                    word = source_oovs[oov_id]\n",
        "                    words.append(word)\n",
        "                except:\n",
        "                    raise IndexError(f'oov id {oov_id} out of range')\n",
        "        return words\n",
        "\n",
        "    def _construct_vocab(self, corpus, size, min_freq):\n",
        "        \n",
        "        vocab = Counter(word for sent in corpus for word in sent.split())\n",
        "        if size is not None:\n",
        "            vocab = {word: freq for (word, freq) in vocab.most_common(size)}\n",
        "        if min_freq is not None:\n",
        "            vocab = {word: freq for (word, freq) in vocab.items() if freq >= min_freq}\n",
        "        \n",
        "        return vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch_Yj1c8Neuc"
      },
      "source": [
        "class DataMaker(object):\n",
        "\n",
        "    def __init__(self, sequences, vocab):\n",
        "\n",
        "        self.sequences = sequences\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max([len(seq.split()) for seq in sequences])\n",
        "        \n",
        "        idx, oovs = [], []\n",
        "        for seqs in sequences:\n",
        "            ids, oov = vocab.source_to_ids(seq.split())\n",
        "            idx.append(ids)\n",
        "            oovs.append(oov)\n",
        "        \n",
        "    def seq_to_ids(self):\n",
        "        idx = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tkt6gwnP6mQ"
      },
      "source": [
        "test = ['i am using keras', 'i prefer tensorflow over pytorch']\n",
        "voc = Vocab(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcX_JJbNuxtC",
        "outputId": "103de3aa-3bda-4727-98de-1432b723ccff"
      },
      "source": [
        "a = 'i started using r yesterday'\n",
        "ids, oovs = voc.source_to_ids(a.split())\n",
        "ids, oovs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2, 10, 4, 11, 12], ['started', 'r', 'yesterday'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAPB5AJ4-IbD",
        "outputId": "1010017f-8d65-4403-9387-d9b47e9a3975"
      },
      "source": [
        "pad = voc.pad_token\n",
        "voc.word_to_id[pad]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "eOogfmvPX3hK",
        "outputId": "0dc41d30-8ab1-476a-b93e-5df3b1093c2f"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Prashant/StudentGradeComment.csv')\n",
        "df.captions = df.captions.apply(lambda text: '<start> ' + text + ' <end>')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attributes</th>\n",
              "      <th>cells</th>\n",
              "      <th>captions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>name gender math reading writing</td>\n",
              "      <td>liam female 72 72 74</td>\n",
              "      <td>&lt;start&gt; liam performance was decent and she wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>name gender math reading writing</td>\n",
              "      <td>noah female 69 90 88</td>\n",
              "      <td>&lt;start&gt; noah scored good in reading and writin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>name gender math reading writing</td>\n",
              "      <td>william female 90 95 93</td>\n",
              "      <td>&lt;start&gt; william was one of the top performers ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>name gender math reading writing</td>\n",
              "      <td>james male 47 57 44</td>\n",
              "      <td>&lt;start&gt; james performed poorly across all thre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>name gender math reading writing</td>\n",
              "      <td>oliver male 76 78 75</td>\n",
              "      <td>&lt;start&gt; oliver was consistent and with more ef...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         attributes  ...                                           captions\n",
              "0  name gender math reading writing  ...  <start> liam performance was decent and she wa...\n",
              "1  name gender math reading writing  ...  <start> noah scored good in reading and writin...\n",
              "2  name gender math reading writing  ...  <start> william was one of the top performers ...\n",
              "3  name gender math reading writing  ...  <start> james performed poorly across all thre...\n",
              "4  name gender math reading writing  ...  <start> oliver was consistent and with more ef...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VkpHSOBYTpE"
      },
      "source": [
        "attr_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk_a>')\n",
        "attr_tokenizer.fit_on_texts(df['attributes'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6AvDY_gioFm"
      },
      "source": [
        "cell_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk_c>')\n",
        "cell_tokenizer.fit_on_texts(df['cells'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdTmvfSnjuCJ"
      },
      "source": [
        "targ_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n",
        "targ_tokenizer.fit_on_texts(df['captions'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVwvJ4e-lETb"
      },
      "source": [
        "attr_input = attr_tokenizer.texts_to_sequences(df['attributes'])\n",
        "attr_input = tf.keras.preprocessing.sequence.pad_sequences(attr_input, padding='post')\n",
        "\n",
        "cell_input = cell_tokenizer.texts_to_sequences(df['cells'])\n",
        "cell_input = tf.keras.preprocessing.sequence.pad_sequences(cell_input, padding='post')\n",
        "\n",
        "targ_input = targ_tokenizer.texts_to_sequences(df['captions'])\n",
        "targ_input = tf.keras.preprocessing.sequence.pad_sequences(targ_input, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwlU7DSXOz5-",
        "outputId": "d99abd46-38d6-4efb-a60c-1b7f2c2b4b4b"
      },
      "source": [
        "attr_input.shape, cell_input.shape, targ_input.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 5), (100, 5), (100, 23))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wnQD213SUWF"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((attr_input,cell_input,targ_input))\n",
        "dataset = dataset.shuffle(32).batch(32, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxwvPlMFCxwu"
      },
      "source": [
        "class InteractiveEncoder(tf.keras.Model):\n",
        "    '''\n",
        "    Arguments:-\n",
        "        attr_vocab_size : (int) Size of field or attribute vocabulary\n",
        "        attr_embedding_size : (int) attribute embedding size\n",
        "        vocab_size: (int) Size of word vocabulary\n",
        "        embedding_size: (int) word embedding size\n",
        "        encoder_size: (int) Dimensions of encoder hidden state\n",
        "        batch_size: (int) Batch size\n",
        "    '''\n",
        "\n",
        "    def __init__(self, attr_vocab_size, attr_embedding_size, vocab_size, embedding_size, encoder_size, batch_size):\n",
        "        super(InteractiveEncoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.encoder_size = encoder_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.attr_vocab_size = attr_vocab_size\n",
        "        self.attr_embedding_size = attr_embedding_size\n",
        "\n",
        "        # attr_embedding_input_shape = (batch_size, enc_length)\n",
        "        self.Attr_Embedding = tf.keras.layers.Embedding(attr_vocab_size, attr_embedding_size)\n",
        "        # attr_embedding_output_shape = (batch_size, enc_length, attr_embedding_size)\n",
        "\n",
        "        # embedding_input_shape = (batch_size, enc_length)\n",
        "        self.Embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        # embedding_output_shape = (batch_size, enc_length, embedding_size)\n",
        "        \n",
        "        # input_shape = (batch_size, enc_length, None)\n",
        "        self.W_e = tf.keras.layers.Dense(encoder_size, use_bias=True)\n",
        "        # output_shape = (batch_size, enc_length, encoder_size)\n",
        "    \n",
        "    def call(self, attr_input, cell_input):\n",
        "\n",
        "        # attr_input --> (batch_size, enc_length)\n",
        "        attr_embed_output = self.Attr_Embedding(attr_input)\n",
        "        # attr_embed_output --> (batch_size, enc_length, attr_embedding_size)\n",
        "        \n",
        "        # cell_input --> (batch_size, enc_length)\n",
        "        cell_embed_output = self.Embedding(cell_input)\n",
        "        # embed_output --> (batch_size, enc_length, embedding_size)\n",
        "\n",
        "        concat_embeds = tf.concat([cell_embed_output, attr_embed_output], axis=2)\n",
        "        # concat_embeds --> (batch_size, enc_length, embedding_size+attr_embedding_size)\n",
        "\n",
        "        output = tf.nn.tanh(self.W_e(concat_embeds))\n",
        "        # output --> (batch_size, seq_length, encoder_size)\n",
        "        \n",
        "        hidden = tf.reduce_mean(output, axis=1)\n",
        "        # hidden --> (batch_size, encoder_size)\n",
        "\n",
        "        return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGbhvokmDEWx"
      },
      "source": [
        "class InteractiveAttn(tf.keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self, units):\n",
        "        super(InteractiveAttn, self).__init__()\n",
        "        \n",
        "        self.units = units \n",
        "        # keep attention units same as decoder_size\n",
        "        \n",
        "        # for intermediate decoder hidden state \n",
        "        self.interGRU = tf.keras.layers.GRU(units, return_sequences=True, return_state=True)\n",
        "        \n",
        "        # for attention scoring\n",
        "        self.W1 = tf.keras.layers.Dense(units) # --> (, decoder_size)\n",
        "        self.W2 = tf.keras.layers.Dense(units) # --> (, decoder_size)\n",
        "        self.v = tf.keras.layers.Dense(1) # --> (, 1)\n",
        "        \n",
        "    def call(self, dec_prev_input_embed, dec_prev_hidden, enc_prev_output):\n",
        "        \n",
        "        # enc_prev_output --> (batch_size, enc_length, encoder_size)\n",
        "        # its a time dependent pseudo encoder output derived from actual/prev encoder output\n",
        "        # dec_prev_hidden --> (batch_size, decoder_size)\n",
        "        # dec_prev_input_embed --> (batch_size, 1, embedding_size)\n",
        "        _, dec_inter_hidden = self.interGRU(dec_prev_input_embed, initial_state=dec_prev_hidden)\n",
        "        # dec_inter_hidden --> (batch_size, decoder_size)\n",
        "        dec_inter_hidden_ = tf.expand_dims(dec_inter_hidden, axis=1)\n",
        "        # dec_inter_hidden_ --> (batch_size, 1, decoder_size)\n",
        "        \n",
        "        score = self.v(tf.nn.tanh(self.W1(dec_inter_hidden_) + self.W2(enc_prev_output)))\n",
        "        # score --> (1)'((batch_size, 1, decoder_size) + (batch_size, enc_length, decoder_size))\n",
        "        # score --> (1)'(batch_size, enc_length, decoder_size) [broadcasting over axis 1]\n",
        "        # score --> (batch_size, enc_length, 1)\n",
        "        \n",
        "        attn_weights = tf.nn.softmax(score, axis=1)\n",
        "        # attn_weights --> (batch_size, enc_length, 1) [floats between 0 and 1]\n",
        "        \n",
        "\n",
        "        context_vector = tf.reduce_sum(attn_weights*enc_prev_output, axis=1)\n",
        "        # attention_weights*encoder_output --> (batch_size, enc_length, encoder_size)\n",
        "        # context_vector --> (batch_size, encoder_size)\n",
        "        \n",
        "        return context_vector, attn_weights, dec_inter_hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkY10mdADLLg"
      },
      "source": [
        "class InteractiveDecoder(tf.keras.Model):\n",
        "    '''\n",
        "    Arguments:-\n",
        "        vocab_size: (int) Size of target vocabulary\n",
        "        embedding_size: (int) Embedding size\n",
        "        decoder_size: (int) Dimensions of decoder hidden state\n",
        "        batch_size: (int) Batch size\n",
        "        attention_style: attention mechanism, 'bahdanau' or 'luong'\n",
        "    '''\n",
        "    def __init__(self, vocab_size, embedding_size, encoder_size, decoder_size, batch_size):\n",
        "        super(InteractiveDecoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.encoder_size = encoder_size\n",
        "        self.decoder_size = decoder_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # embedding_input_shape = (batch_size, 1) [seq_length = 1 for decoder]\n",
        "        self.Embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        # embedding_output_shape = (batch_size, 1, embedding_size)\n",
        "\n",
        "        # gru_input_shape = (batch_size, 1, embedding_size+...)\n",
        "        self.GRU = tf.keras.layers.GRU(decoder_size, \n",
        "                                       return_sequences=True, \n",
        "                                       return_state=True)\n",
        "        # output_shape = (batch_size, 1, decoder_size)\n",
        "        # hidden_state_shape = (batch_size, decoder_size)\n",
        "\n",
        "        self.Linear = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = InteractiveAttn(decoder_size)\n",
        "        \n",
        "        # to derive new pseudo encoder output\n",
        "        self.Wf = tf.keras.layers.Dense(encoder_size) # --> (, encoder_size)\n",
        "        self.Wu = tf.keras.layers.Dense(encoder_size) # --> (, encoder_size)\n",
        "\n",
        "    def call(self, dec_prev_input, dec_prev_hidden, enc_prev_output):\n",
        "\n",
        "        # dec_prev_input --> (batch_size, 1) [dec_length = 1 for decoder]\n",
        "        dec_prev_input_embed = self.Embedding(dec_prev_input)\n",
        "        # dec_prev_input_embed --> (batch_size, 1, embedding_size)\n",
        "\n",
        "        # prev_enc_output --> (batch_size, enc_length, encoder_size)\n",
        "        # dec_prev_hidden --> (batch_size, decoder_size)\n",
        "        context_vector, attn_weights, dec_inter_hidden = self.attention(dec_prev_input_embed, \n",
        "                                                                        dec_prev_hidden, \n",
        "                                                                        enc_prev_output)\n",
        "        # context_vector --> (batch_size, encoder_size)\n",
        "        # attn_weights --> (batch_size, enc_length, 1)\n",
        "        # dec_inter_hidden --> (batch_size, decoder_size)\n",
        "        \n",
        "        # --------constructing new pseudo encoder output----------\n",
        "\n",
        "        context_vector_ = tf.expand_dims(context_vector, axis=1)\n",
        "        # context_vector_ --> (batch_size, 1, encoder_size)\n",
        "\n",
        "        output_, dec_curr_hidden = self.GRU(context_vector_, initial_state=dec_inter_hidden)\n",
        "        # output_ --> (batch_size, 1, decoder_size)\n",
        "        # dec_curr_hidden --> (batch_size, decoder_size)\n",
        "        \n",
        "        enc_length = enc_prev_output.shape[1]\n",
        "        # (a) Forget Part\n",
        "        F = tf.nn.sigmoid(self.Wf(dec_curr_hidden))\n",
        "        F = tf.expand_dims(F, axis=1)\n",
        "        F = tf.tile(F, [1,enc_length,1])\n",
        "        # F --> (batch_size, enc_length, encoder_size)\n",
        "        \n",
        "        # (a) Update Part\n",
        "        U = tf.nn.sigmoid(self.Wu(dec_curr_hidden))\n",
        "        U = tf.expand_dims(U, axis=1)\n",
        "        U = tf.tile(U, [1,enc_length,1])\n",
        "        # U --> (batch_size, enc_length, encoder_size)\n",
        "        \n",
        "        # (c) New (pseudo) encoder output\n",
        "        enc_curr_output = enc_prev_output*(1-attn_weights*F) + attn_weights*U\n",
        "        \n",
        "        output_ = tf.squeeze(output_, axis=1)\n",
        "        # output --> (batch_size, decoder_size)\n",
        "        output = tf.nn.softmax(self.Linear(output_))\n",
        "        # output --> (batch_size, vocab_size)\n",
        "        return output, dec_curr_hidden, enc_curr_output, context_vector, dec_prev_input_embed, attn_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEq8pD9ADRFV"
      },
      "source": [
        "class Table2Text(object):\n",
        "    \n",
        "    def __init__(self, attr_vocab_size, attr_embedding_size, \n",
        "                 cell_vocab_size, cell_embedding_size, \n",
        "                 targ_vocab_size, targ_embedding_size, \n",
        "                 encoder_size, decoder_size, batch_size):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        self.targ_vocab_size = targ_vocab_size\n",
        "        self.history = dict()\n",
        "\n",
        "        self.encoder = InteractiveEncoder(attr_vocab_size, attr_embedding_size, \n",
        "                                          cell_vocab_size, cell_embedding_size, \n",
        "                                          encoder_size, batch_size)\n",
        "        self.decoder = InteractiveDecoder(targ_vocab_size, targ_embedding_size, \n",
        "                                          encoder_size, decoder_size, batch_size)\n",
        "        \n",
        "        self.Wg = tf.keras.layers.Dense(1, use_bias=True)\n",
        "        \n",
        "        self.optimizer = tf.keras.optimizers.Adam()\n",
        "        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                                         reduction='none')\n",
        "        \n",
        "    \n",
        "    def loss_function(self, real, pred):\n",
        "        \n",
        "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "        loss_ = self.loss_object(real, pred)\n",
        "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "        loss_ *= mask\n",
        "\n",
        "        return tf.reduce_mean(loss_)\n",
        "    \n",
        "    def _retrieve_attr(self, attr_input, cell_input, dec_prev_input):\n",
        "        \n",
        "        attr = attr_input.numpy()\n",
        "        cell = cell_input.numpy()\n",
        "        targ = dec_prev_input.numpy()\n",
        "        enc_length = cell_input.shape[1]\n",
        "        cell[cell != np.tile(targ, [1,enc_length])] = 0\n",
        "        cell[cell != 0] = 1\n",
        "        attr_retrieved = tf.reduce_max(attr*cell, axis=1)\n",
        "        \n",
        "        return attr_retrieved\n",
        "\n",
        "    #@tf.function\n",
        "    def train_step(self, attr_input, cell_input, targ, live_pred):\n",
        "        \n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = self.encoder(attr_input, cell_input)\n",
        "            \n",
        "            enc_prev_output, dec_prev_hidden = enc_output, enc_hidden\n",
        "            dec_prev_input = tf.expand_dims([targ_tokenizer.word_index['<start>']]*self.batch_size, axis=1)\n",
        "            \n",
        "            pred_batch = dec_prev_input\n",
        "            pred_batch = tf.cast(pred_batch, dtype=tf.int32)\n",
        "            # Teacher forcing - feeding the target as the next input\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                # passing enc_output to the decoder\n",
        "                beta, dec_curr_hidden, enc_curr_output, context_vector, dec_prev_input_embed, attn_weights = self.decoder(dec_prev_input, \n",
        "                                                                                                            dec_prev_hidden, \n",
        "                                                                                                            enc_prev_output)\n",
        "                                                                                                 \n",
        "                \n",
        "                attr_retrieved = self._retrieve_attr(attr_input, cell_input, dec_prev_input)\n",
        "                attr_retrieved_embed = self.encoder.Attr_Embedding(attr_retrieved)\n",
        "                dec_prev_input_embed = tf.squeeze(dec_prev_input_embed, axis=1)\n",
        "        \n",
        "                g_inp = tf.concat([dec_prev_input_embed, \n",
        "                                   dec_curr_hidden, \n",
        "                                   context_vector, \n",
        "                                   enc_hidden, \n",
        "                                   attr_retrieved_embed], axis=1)\n",
        "                g_out = tf.nn.sigmoid(self.Wg(g_inp))\n",
        "\n",
        "                alpha = tf.squeeze(attn_weights, axis=2)\n",
        "                pred = tf.concat([(1-g_out)*beta, g_out*alpha], axis=1)\n",
        "                # pred --> (batch_size, targ_vocab_size+enc_lenght)\n",
        "                loss += self.loss_function(targ[:, t], pred)\n",
        "                new_pred = tf.expand_dims(tf.argmax(pred, axis=1, output_type=tf.int32), axis=1)\n",
        "                pred_batch = tf.concat([pred_batch,new_pred], axis=1)\n",
        "                # using teacher forcing\n",
        "                dec_prev_input = tf.expand_dims(targ[:, t], 1)\n",
        "                enc_prev_output, dec_prev_hidden = enc_curr_output, dec_curr_hidden\n",
        "\n",
        "        batch_loss = (loss/int(targ.shape[1]))\n",
        "        variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        if live_pred:\n",
        "            self._rand_prediction(pred_batch,targ)\n",
        "\n",
        "        return batch_loss\n",
        "    \n",
        "    def val_step(self, attr_input, cell_input, targ, live_pred):\n",
        "\n",
        "        loss = 0\n",
        "        enc_output, enc_hidden = self.encoder(attr_input, cell_input)\n",
        "\n",
        "        enc_prev_output, dec_prev_hidden = enc_output, enc_hidden\n",
        "        dec_prev_input = tf.expand_dims([targ_tokenizer.word_index['<start>']]*self.batch_size, axis=1)\n",
        "        pred_batch = dec_prev_input\n",
        "        pred_batch = tf.cast(pred_batch, dtype=tf.int32)\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            beta, dec_curr_hidden, enc_curr_output, context_vector, dec_prev_input_embed, attn_weights = self.decoder(dec_prev_input, \n",
        "                                                                                                        dec_prev_hidden, \n",
        "                                                                                                        enc_prev_output)\n",
        "\n",
        "\n",
        "            attr_retrieved = self._retrieve_attr(attr_input, cell_input, dec_prev_input)\n",
        "            attr_retrieved_embed = self.encoder.Attr_Embedding(attr_retrieved)\n",
        "            dec_prev_input_embed = tf.squeeze(dec_prev_input_embed, axis=1)\n",
        "\n",
        "            g_inp = tf.concat([dec_prev_input_embed, \n",
        "                               dec_curr_hidden, \n",
        "                               context_vector, \n",
        "                               enc_hidden, \n",
        "                               attr_retrieved_embed], axis=1)\n",
        "            g_out = tf.nn.sigmoid(self.Wg(g_inp))\n",
        "\n",
        "            alpha = tf.squeeze(attn_weights, axis=2)\n",
        "            pred = tf.concat([(1-g_out)*beta, g_out*alpha], axis=1)\n",
        "            # pred --> (batch_size, targ_vocab_size+enc_lenght)\n",
        "\n",
        "            loss += self.loss_function(targ[:, t], pred)\n",
        "            \n",
        "            # not using teacher forcing\n",
        "            pred_id = tf.argmax(pred, axis=1)\n",
        "            pred_id = tf.expand_dims(pred_id, 1) # problem if pred_id is beyond vocab size\n",
        "            pred_id_ = pred_id.numpy()\n",
        "            pred_id_[pred_id_ > self.targ_vocab_size] = targ_tokenizer.word_index['<unk>']\n",
        "            dec_prev_input = tf.convert_to_tensor(pred_id_, dtype=tf.int32)\n",
        "            pred_batch = tf.concat([pred_batch,dec_prev_input], axis=1)\n",
        "            enc_prev_output, dec_prev_hidden = enc_curr_output, dec_curr_hidden\n",
        "\n",
        "        batch_loss = (loss/int(targ.shape[1]))\n",
        "        if live_pred:\n",
        "            self._rand_prediction(pred_batch,targ)\n",
        "\n",
        "        return batch_loss\n",
        "    \n",
        "    def _rand_prediction(self, pred, targ=None, idx=None):\n",
        "        \n",
        "        idx = np.random.randint(0,pred.shape[0]) if idx is None else idx\n",
        "        \n",
        "        if targ is not None:\n",
        "            targ_s = targ_tokenizer.sequences_to_texts([targ.numpy()[idx][1:]])[0]\n",
        "            #targ_s = ' '.join(targ_s)\n",
        "            targ_s = re.sub('[_$$_]', ' ', targ_s)\n",
        "            targ_s = re.sub('\\s+', ' ', targ_s)\n",
        "            print('(Reference) ', targ_s)\n",
        "        pred_s = targ_tokenizer.sequences_to_texts([pred.numpy()[idx][1:]])[0]\n",
        "        #pred_s = ' '.join(pred_s)\n",
        "        pred_s = re.sub('[_$$_]', ' ', pred_s)\n",
        "        pred_s = re.sub('\\s+', ' ', pred_s)\n",
        "        print('(Generated) ', pred_s)\n",
        "    \n",
        "    def fit(self, train_set, epochs, val_set=None, live_pred=True):\n",
        "        \n",
        "        for i in range(epochs):\n",
        "            train_loss = 0\n",
        "            for (batch, (attr, cell, targ)) in enumerate(train_set.take(1)):\n",
        "                batch_loss = self.train_step(attr, cell, targ, live_pred)\n",
        "                print('train batch loss: ',batch_loss)\n",
        "                train_loss += batch_loss\n",
        "            try:\n",
        "                self.history['train'].append(train_loss)\n",
        "            except:\n",
        "                self.history['train'] = [train_loss]\n",
        "\n",
        "            if val_set is not None:\n",
        "                val_loss = 0\n",
        "                for (batch, (attr, cell, targ)) in enumerate(val_set.take(1)):\n",
        "                    batch_loss = self.val_step(attr, cell, targ, live_pred)\n",
        "                    print('val batch loss: ',batch_loss)\n",
        "                    val_loss += batch_loss\n",
        "                try:\n",
        "                    self.history['val'].append(val_loss)\n",
        "                except:\n",
        "                    self.history['val'] = [val_loss]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80mmAjUpX_eM"
      },
      "source": [
        "model = Table2Text(attr_vocab_size=len(attr_tokenizer.word_index)+1, \n",
        "                attr_embedding_size=4, \n",
        "                cell_vocab_size=len(cell_tokenizer.word_index)+1, \n",
        "                cell_embedding_size=16, \n",
        "                targ_vocab_size=len(targ_tokenizer.word_index)+1, \n",
        "                targ_embedding_size=16, \n",
        "                encoder_size=64, \n",
        "                decoder_size=64, \n",
        "                batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkC3Afv4F79c"
      },
      "source": [
        "model.fit(dataset, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC8xbcI2pTFZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}